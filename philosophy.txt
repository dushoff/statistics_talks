
EXTRA 2017 notes

* https://twitter.com/mlipsitch/status/838494026726789125. Dangers of under-powered studies. Outside the scope

* https://twitter.com/ken_rothman/status/862016511724183553 Debates about a JAMA that accepted the null hypothesis. Fun but not necessary.

* http://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124 Why most published research findings are false. Good, but a null-hypothesis believer. Outside the scope.

* Non-inferiority trial example’s great but probably went to fast for most of the audience
* MMEV: Need to have 1 slide with all the relevant info (ie, add the Question you’ve posed to the Example slide!)

* for pred value positive, give extreme where there’s 0% prevalence to make it clear

----------------------------------------------------------------------

NOFRAME

\newcommand{\jdtitle}{Statistical philosophy}
\newcommand{\jdsub}{}
\newcommand{\years}{2012--\thisyear} 

----------------------------------------------------------------------

THEMETITLE

----------------------------------------------------------------------

PLAIN Statistical philosophy

PRESENT \vfill\begin{center} 

Jonathan Dushoff, McMaster University

RESTING \url{http://lalashan.mcmaster.ca/DushoffLab}

PRESENT \vfill

PRESENT 2024 QMEE version

RESTING \vfill

RESTING National Taiwan University

PRESENT \vfill\end{center}

----------------------------------------------------------------

GOALS

	Discuss what statistics are used for, and why they are needed

	Explain what P values mean, and what they don't

		Effect sizes and confidence intervals are usually better

	Explain the fundamentals of the two basic paradigms of statistical philosophy

	Discuss the role of statistics in science

----------------------------------------------------------------------

OTHER NSLIDE Statistical philosophy

	Jonathan Dushoff, McMaster University

	HREF http://dushoff.github.io/notebook/materials/philosophy.handouts.pdf Download pdf notes (should be this version)

	HREF http://dushoff.github.io/notebook/materials/philosophy.draft.pdf Download pdf slides (from some recent version)

----------------------------------------------------------------------

PSLIDE Long pipe 

PIC HFIG 0.5 webpix/pipe.jpg

	Any piece of pipe longer than 30 feet shall be clearly labelled
	``long pipe'' on each end

	Any piece of pipe longer than 100 feet shall also be labelled
	``long pipe'' in the middle, so the plumber doesn't have to walk all
	the way to the end to find out whether it is long pipe or not.

	\textbf{WARNING: Long Lecture}

----------------------------------------------------------------------

TSEC Statistical inference

	We use statistics to confirm effects, estimate parameters, and
	predict outcomes

	It usually rains when I'm in Cape Town, but mostly on Sunday

		\emph{Confirmation:} In Cape Town, it rains more on Sundays than
		other days

		\emph{Estimation:} In Cape Town, the \emph{odds} of rain on
		Sunday are 1.6--2.2 times higher than on other days

		\emph{Prediction:} I am confident that it will rain at least one
		Sunday the next time I go

----------------------------------------------------------------------

Raining in Cape Town

BC

	How we interpret data like this necessarily depends on assumptions:

		Is it likely our observations occured by chance?

		Is it likely they \emph{didn't}?

NC

PIC HFIG 0.8  my_images/eight.jpg

PIC CREDIT Tessa Wessels, {\em Faces on a Train}

EC

----------------------------------------------------------------------

Vitamin A

	We compare health indicators of children treated or not treated with
	vitamin A supplements 

		\emph{Estimate:} how much taller (or shorter) are the treated
		children on average?

		\emph{Confirmation:} are we sure that the supplements are helping
		(or hurting)?

		\emph{Range of estimates:} how much do we think the supplement is
		helping?

----------------------------------------------------------------------

TSS P values and confidence intervals

	We use \emph{P values} to say how sure we are that we have seen a positive 
	effect

	We use \emph{confidence intervals} to say what we think is going on
	(with a certain level of confidence)

	P values are \emph{over-rated}

	\emph{Never} use a high P value as (direct) evidence for anything, e.g.:
	
		that an effect is small

		that two quantities are similar

----------------------------------------------------------------------

Vitamin A example

	We want to know if vitamin A supplements improve the health of
	village children

		Is height is a good measure of general health?

		How will we know height differences are due to our treatment?

			ANS We want the two groups to start from the same point --
			independent randomization of each individual

			ANS We may measure \emph{changes} in height

			ANS Or \emph{control for} height (and maybe other factors)

----------------------------------------------------------------------

What do we hope to learn?

	Is vitamin A good for these children?

	How sure are we?

	How good do we think it is?

	How sure are we about that?

----------------------------------------------------------------------

P values

	What does it mean if I find a "significant P value" for some effect
	in this experiment?

	ANS The difference is unlikely to be due to chance

		ANS So what!  I already know vitamin A has strong effects on
		metabolism

	If I'm certain that the true answer isn't exactly zero, why do I
	want the P value anyway?

----------------------------------------------------------------------

Confidence intervals

BC

CFIG vitamins.Rout-0.pdf

NC

	What do these results mean?

	Which are significant?

EC

----------------------------------------------------------------------

Confidence intervals and P values

BC

PRESENT CFIG vitamins.Rout-1.pdf

NC

	A high P value means we can't see the sign of the effect clearly

	A low P value means we can

EC

----------------------------------------------------------------------

What do P values measure?

PIC DBFIG 0.8 webpix/fog.jpg 1 webpix/clear.jpg

	ANS Clarity!

	ANS We should call it that

----------------------------------------------------------------------


Types of Error

	Type I (\emph{False positive:}) concluding there is an effect when
	there isn't one

		This doesn't happen in biology.  There is always an effect.

	Type II (\emph{False negative:}) concluding there is no effect when
	there really is

		This \emph{should} never happen, because we should never conclude
		there is no effect

----------------------------------------------------------------------

RHEAD Types of Error

	Type III Error is the error of using numerical codes for things that have perfectly good simple names

	Just say ``false positive'' or ``false negative'' when possible

----------------------------------------------------------------------

Experimental design

	\emph{False positive:} in the hypothetical case that the
	effect is exactly zero, what is the probability of falsely finding
	an effect

		Should be less than or equal to my significance value

	\emph{False negative:} what is the probability of failing
	to find an effect that is there?

		Requires you specify a hypothetical effect \emph{size}

		This is a scientific judgment

	These are useful to analyze \textbf{power} and \textbf{validity} of a
	statistical design
	
		You should do these analyses \emph{before} you collect data

----------------------------------------------------------------------

Doing Science

	I never make a false-negative error:

		ANS I never accept the null

	I never make a false-positive error:

		ANS I never believe the null is exactly true

	\emph{Sign error:} if I think an effect is positive, when it's really
	negative (or vice versa)

	\emph{Magnitude error:} if I think an effect is small, when it's
	really large (or vice versa)

	Confidence intervals clarify all of this

----------------------------------------------------------------------

Low P values

BC

	If I have a low P value I can see something clearly

	But it's usually better to focus on what I see than the P value

NC

SIDEFIG webpix/clear.jpg

EC


----------------------------------------------------------------------

High P values

BC

	If I have a high P value, there is something I \emph{don't} see
	clearly

	It \emph{may be} because this effect is small

	High P values should \emph{not} be used to advance \emph{any} conclusion

NC

SIDEFIG webpix/fog.jpg

EC

----------------------------------------------------------------------

What causes high P values?

	Small differences

	Less data

	More noise

	An inappropriate model

	Less model resolution

	A lower P value means that your evidence for difference is better

	A higher P value means that your evidence for similarity is
	better -- or worse!

----------------------------------------------------------------------

Annualized flu deaths

BC

CFIG flu.Rout-0.pdf

NC

	Why is weather not causing deaths at this time scale?

EC

----------------------------------------------------------------------

DEFHEAD ... with confidence intervals

BC

CFIG flu.Rout-1.pdf

NC

	\textbf{Never} say: A is significant and B isn't, so $A>B$

	\textbf{Instead:} Construct a statistic for the hypothesis $A>B$

		May be difficult

EC

----------------------------------------------------------------------

Bad language

	Null effects of boot camps

		ANS Wrong!

	Fat storage in vole populations is not correlated with elevation

		ANS Yes, it is!

	As expected, the placebo group did not differ significantly from the control
	group

		ANS Why would that be good?

	B and B showed that there is no statistically significant
	difference in sexual risk behaviour between men with and without clinic
	access in Zambia

		ANS No, they didn't

		ANS Statistical significance is a property of the \emph{study} (and the
		sample population), never of real groups (or the idealized population)

----------------------------------------------------------------------

Another way to talk

	Unclear effects of boot camps

	As expected, the sign of the difference between the placebo group and
	controls was unclear

		ANS Is this convincing? Will it remind people to check the size of
		difference?

	The direction of correlation between fat storage and elevation in
	vole populations is unclear in this study

	B and B showed that there is an unclear difference in sexual risk
	behaviour between men with and without clinic access in Zambia

		ANS Now obviously weird. So you have to say it better

----------------------------------------------------------------------


SS Statistics and science

----------------------------------------------------------------------

Syllogisms

BC

	All men are mortal

	Mohamed Salah is mortal

	Therefore, Mohamed Salah is a man

NC

SIDEFIG webpix/salah.jpg

EC

----------------------------------------------------------------------

Syllogisms

BC

	All men are mortal

	Fanny the elephant is mortal

	Therefore, Fanny the elephant is a man

NC

SIDEFIG webpix/fanny.jpg

EC

----------------------------------------------------------------------

Bad logic

	A lot of statistical practice works this way:

		bad logic in service of conclusions that are (usually) correct

	This sort of statistical practice leads in the aggregate to bad
	science

	The logic can be fixed:

		Estimate a difference, or an interaction

----------------------------------------------------------------------

Small effects

	We can't build statistical confidence that something is small by
	failing to see it clearly

	We must instead see clearly that it is small

	This means we need a standard for what we mean by small

----------------------------------------------------------------------

PSLIDE Flu masks 

DBFIG 0.8 webpix/N95.jpg 0.7 webpix/surgical.jpg

----------------------------------------------------------------------

Flu mask example

	People who work in respiratory clinics sometimes have to wear bulky,
	uncomfortable, expensive masks

	They would like to switch to simpler masks, if those will do the job

	How can this be tested statistically?  We don't want the masks to be
	"different".

		We need to decide what we mean by different in this case!

		They're not the same, so how close is close enough?

----------------------------------------------------------------------

Tradiitonal approach

FIG masks.Rout-2.pdf

----------------------------------------------------------------------

Non-inferiority approach

BC

PRESENT CFIG masks.Rout-0.pdf

NC

	Are we confident the new mask is ``good enough''?

	There is no substitute for picking a standard

EC

----------------------------------------------------------------------

Non-inferiority approach

BC

CFIG masks.Rout-1.pdf

NC

	We can even attach a P value by basing it on the ``right" statistic.

	The right statistic is the thing whose sign we want to know:

		The difference between the observed effect and the standard we
		chose

EC

----------------------------------------------------------------------

SEC Paradigms for inference

----------------------------------------------------------------------

TSS Frequentist paradigm

	Make a null model

	Test whether the effect you see could be due to chance

		What is the probability of seeing a difference of exactly 0.0048 in
		proportional growth?

			ANS Zero!

	Test whether the effect you see {\em or a larger effect}** could be
	due to chance

		This probability is the P value

	** It's actually better to calculate a one-sided P value. You would then
	usually double this to get a standard P value

----------------------------------------------------------------------

Height measurements

FIG vitamins_plot.Rout-0.pdf

----------------------------------------------------------------------

Scrambled measurements

FIG vitamins_plot.Rout-1.pdf

----------------------------------------------------------------------

PSLIDE Scrambled measurements

FIG vitamins_plot.Rout-2.pdf

----------------------------------------------------------------------

PSLIDE Scrambled measurements

FIG vitamins_plot.Rout-3.pdf

----------------------------------------------------------------------

PSLIDE Scrambled measurements

FIG vitamins_plot.Rout-4.pdf

----------------------------------------------------------------------

The null distribution

FIG vitamins_scramble.Rout.pdf

----------------------------------------------------------------------

TSS Bayesian paradigm

BC

	Make a complete model world

	Use conditional probability to calculate the probability you want

NC

SIDEFIG webpix/shanghai.jpg

EC

----------------------------------------------------------------------

A powerful framework

BC

	More assumptions $\implies$ more power

	With great power comes great responsibility

NC

SIDEFIG webpix/spiderman.jpg

EC

----------------------------------------------------------------------

Bayesian inference

	We want to go from a \emph{statistical model} of how our data are
	generated, to a probability model of parameter values

		Requires \emph{prior} distributions:
		
			the assumed likelihood of parameters before these observations are
			made

		Use Bayes theorem to calculate \emph{posterior} distributions:

			the inferred likelihood of parameters after taking the data into
			account

	Provides a strong framework for combining information from different sources
	and for propagating uncertainty

----------------------------------------------------------------------

Vitamin A study

BC

	A frequentist can do a clear analysis right away

	A Bayesian needs a ton of assumptions -- will often try to make
	``uninformative'' assumptions

NC

SIDEFIG vitamins_plot.Rout-0.pdf

EC

----------------------------------------------------------------------

Cape Town weather

BC

	Frequentist: how unlikely is the observation, from a random
	perspective?

	Bayesian: what's my model world?  What is my prior belief about 
	weather-weekday interactions?

NC

PIC HFIG 0.8  my_images/eight.jpg

PRESENT CREDIT Tessa Wessels, {\em Faces on a Train}

EC

----------------------------------------------------------------------

BAYESCALC Example: MMEV 

	MMEV is a viral infection that can cause a serious disease
	(called MMED)
	
	LIT MMED patients are unable to control their urge to fit models to data

	The rapid MMEV test gives a positive result:

		100% of the time for people with the virus
		
		5% of the time for people without the virus

----------------------------------------------------------------------

MMED MMEV questions

	The rapid MMEV test gives a positive result:

		100% of the time for people with the virus
		
		5% of the time for people without the virus

	The population prevalence of MMEV is 1% 

	You pick a person from this population at random, and test them, and
	the test is positive.

		What is the probability that they have MMEV?

	This calculation is the core of Bayes theorem

----------------------------------------------------------------------

MMED MMEV questions

	You learn that your friend has had a positive rapid test for MMEV

		What do you tell them? 

			ANS You don't tell them \emph{anything} until you ask them some
			questions!

	This is what Bayesian philosophy is about: combining information from
	different sources

----------------------------------------------------------------------

SEC Conclusion

----------------------------------------------------------------------

Your philosophy

	Statistics are not a magic machine that gives you the right answer

	If you are to be a serious scientist in a noisy world, you should
	have your own philosophy of statistics

		Be pragmatic: your goal is to do science, not get caught by
		theoretical considerations

		Be honest: it's harder than it sounds.  

----------------------------------------------------------------------

Honesty

	You can always keep analyzing until you find a ``significant''
	result

		If you do this you will make a lot of mistakes

	You may also keep analyzing until you find a result that you already
	believe is true. 

		This is \emph{confirmation bias;} you're probably right, but your project
		is not advancing science

	Good practice

		Keep a data-analysis journal

		Start \emph{before} you look at the data

----------------------------------------------------------------------

PSLIDE Summary

FIG webpix/pipe.jpg

----------------------------------------------------------------------

Summary

	P values are over-rated

	High P values should not be used as evidence for anything ever.

		They can provide indirect evidence. Wonderful. Find the direct
		evidence and use that instead.

	Use effect sizes and confidence intervals when you can

	Otherwise, find ways to make significant P values do the work
	
		Non-inferiority tests, interactions

----------------------------------------------------------------------

RHEAD Summary

	Frequentist statistics makes weak assumptions, and finds logically weak
	formal conclusions:

		These parameters are unlikely to produce a statistic this extreme by
		chance

	Bayesian statistics makes strong assumptions:
	
		prior distributions must be fully specified
		
	\ldots and finds logically strong 
	formal conclusions:

		The probability that the effect value is in this range is X

		These strong conclusions can be used directly for prediction with
		uncertainty

----------------------------------------------------------------------

RHEAD Summary

	Statistics are a key component of data-based science

		You should think about statistical analysis from the beginning of
		your project

	You need a basic understanding of statistical principles

	You need your own statistical philosophy

		If you're a theoretician, it should be ideological and honest

		If you're a scientist, it should be pragmatic and honest
