
EXTRA

Fix EbolaFits

----------------------------------------------------------------------

Model evaluation

\vfill

Jonathan Dushoff, McMaster University

\url{http://lalashan.mcmaster.ca/DushoffLab}

\vfill

DAIDD 2016

\url{http://www.ici3d.org/mmed/}

\vfill

----------------------------------------------------------------------

Do I have a good model?

	What is my model trying to accomplish?

		Generating hypotheses

		Evaluating plausibility

		Prediction

		Extrapolation

		Mechanistic understanding

----------------------------------------------------------------------

Statistical philosophy

FIG Lecture_images/obey_kitties.png

----------------------------------------------------------------------

SEC Conceptual models

----------------------------------------------------------------------

Disease thresholds

FIG curves/propCurves.Rout-0.png

----------------------------------------------------------------------

Effects of clinical immunity

FIG Lecture_images/keeganClinicalDiagram.jpg

----------------------------------------------------------------------

Bistability

WIDEFIG Lecture_images/keeganPhaseDiagram.jpg

----------------------------------------------------------------------

SEC Prediction

----------------------------------------------------------------------

Ptolemy v.\ Copernicus

FIG Lecture_images/epicycles.jpg

----------------------------------------------------------------------

Ptolemy v.\ Copernicus

FIG Lecture_images/heliocentric.jpg

----------------------------------------------------------------------

What causes cholera?

WIDEFIG my_images/Farr.png

----------------------------------------------------------------------

What causes cholera?

FIG Lecture_images/choleraMap.jpg

----------------------------------------------------------------------

TSEC Model Validation

	Does your fitting algorithm match your \emph{model world}?

HFIG 0.4 my_images/modelWorld.png

	If you use your fitting algorithm on simulations from your model
	world, then you \emph{know the right answer}!

----------------------------------------------------------------------

Validation measures

	Coverage

	Precision

	Bias?

	Accuracy?

----------------------------------------------------------------------

Coverage

HFIG 0.5 Lecture_images/SierraLeoneValidation.jpg

	The right answer should be inside your 95% confidence interval 95% of
	the time

		If more, your model is \emph{too conservative}

		If less, your model is \emph{invalid}

	In many cases it's good to look at the two tails separately:

		How often do you overestimate? Underestimate?

----------------------------------------------------------------------

Precision

	You should aim to make your confidence intervals as narrow as
	possible

		Provide as much information as possible

	As data increases, your precision should increase

		CIs should approach zero width

----------------------------------------------------------------------

Bias?

	Nobody wants to be biased 

	You \emph{need} to be \emph{asymptotically} unbiased

		Good coverage and good precision assure this

	Not so clear you need to be \emph{absolutely} unbiased

		Bias is the difference between the \emph{mean} expected prediction and the
		true value

		Scale dependent: an unbiased estimate of $\gamma$ is
		automatically a biased estimate of $D$ (but not
		asymptotically biased)

	It may be better to evaluate using medians (instead of means)

----------------------------------------------------------------------

Accuracy?

	Nobody wants to be inaccurate

	Good coverage and good precision should guarantee good accuracy

----------------------------------------------------------------------

TSEC Model Evaluation

	Does your model match the \emph{real world}?

PIC HFIG 0.7 Lecture_images/Earth.jpg

----------------------------------------------------------------------

TSS Goodness of fit

	Goodness of fit \emph{statistics} describe how well a model prediction
	matches observed data

	Goodness of fit \emph{tests} attempt to determine whehter the observed
	difference between model and data is statistically significant

----------------------------------------------------------------------

EXTRA A disease-incidence model

COMMENT Do I like this? Am I thinking clearly about it?

I like the picture at least.

SUBH Good for almost any disease

BC

HFIG 0.75 Lecture_images/godDice.jpg

NC

	The gods roll dice to pick a probability between 0.1% and 10%.

	Each person on the planet gets the disease the next year with this
	probability

	$P>0.05$. My model is correct!

EC

----------------------------------------------------------------------

Your model is false!

BC

	A goodness of fit test won't make it true

	You can ``pass'' a goodness of fit test by:

		having a good model

		making very broad predictions

		having bad data

		choosing an inappropriate way to compare

	So why do we use P values at all in biology?

NC

CFIG Lecture_images/godDice.jpg

EC

----------------------------------------------------------------------

Vitamin study

FIG vitamins.Rout-0.pdf

----------------------------------------------------------------------

Vitamin study

FIG vitamins.Rout-1.pdf

----------------------------------------------------------------------

Low P values

FIG Lecture_images/clear.jpg

----------------------------------------------------------------------

High P values

FIG Lecture_images/fog.jpg

----------------------------------------------------------------------

Goodness of fit test

	Your model is \emph{not} reality (null hypothesis is false)

	Can we see the difference clearly?

		If no, model may be good or bad. 
		
			We probably can't add any more complexity based on current
			data

		If yes, model may be good or bad. We \emph{may} be able to add more
		complexity based on current data

			But we may not need to

----------------------------------------------------------------------

TSS Capturing patterns

	You can ask:

		Does your model do a reasonable job of capturing the data?

			You can use a goodness of fit \emph{statistic} for this, and not
			worry about the P value

		Does your model capture patterns and relationships that you (or
		other experts) think are important?

----------------------------------------------------------------------

SS Going beyond

----------------------------------------------------------------------

Out-of-sample validation

	Does your model make predictions \emph{outside} the range on which you
	calibrated it?

		Predicting gravitational shifts in star positions from
		measurements in Earth laboratories

		Predicting cholera outbreaks in Bangladesh from a model calibrated
		to Haiti

		Predicting influenza patterns in 2010 from a model calibrated from
		2000--2009

----------------------------------------------------------------------

Test sets

	What is \textbf{test set} spelled backwards?

	Hold some data out while fitting your model

	Or just \emph{pretend} to do this as an evaluation method

		In other words, test what would happen under various withholding
		scenarios

----------------------------------------------------------------------

Other model worlds

	The model you're \emph{fitting} is probably pretty simple

	But you can \emph{simulate} very complicated models, indeed

HFIG 0.6 Lecture_images/legoland.jpg

	How well can you do? Which details are important?

----------------------------------------------------------------------

Other model worlds

FIG EbolaFits/T34.NIH3.compare.Rout-0.pdf

----------------------------------------------------------------------

Other model worlds

FIG EbolaFits/T34.NIH3.compare.Rout-1.pdf

----------------------------------------------------------------------

Generating hypotheses

FIG Lecture_images/EbolaBurial.jpg

----------------------------------------------------------------------

Generating hypotheses

FIG Lecture_images/lembo_spp.jpg

----------------------------------------------------------------------

Testing hypotheses

WIDEFIG my_images/Farr.png

----------------------------------------------------------------------

Testing hypotheses

FIG Lecture_images/choleraMap.jpg

----------------------------------------------------------------------

Testing hypotheses

FIG Lecture_images/BroadStreet.jpg

----------------------------------------------------------------------

Hard questions

FIG Lecture_images/QuestionAnswers.jpg

----------------------------------------------------------------------

SEC Conclusion

----------------------------------------------------------------------

Dynamic models can help:

	Think clearly

	Understand outcomes

	Predict outcomes

	Find new mechanisms

----------------------------------------------------------------------

Evaluation

	Validation (inside your model world)

	Inspection (compare patterns)

	Prediction (and other out-of-sample comparison)

	Generate and test hypotheses

----------------------------------------------------------------------

Conclusion

HFIG 0.7 Lecture_images/prometheus.jpg

\vfill

Essentially, all models are wrong, but some are useful.

-- Box and Draper (1987), \emph{Empirical Model Building \ldots}

\vfill
