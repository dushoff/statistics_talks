
EXTRA Abstract

## Statistical philosophy and the language of significance

Chicago abstract: Fuzzy thinking about statistical inference is common not only
in science, but even among statisticians. I will give some thoughts about a
simple statistical philosophy, and argue that a change in language may help, or
at least not hurt.

## Is Statistical ``Significance" a Thing?}

Stats seminar abstract: I will discuss statistical philosophy for scientists, and how it should differ from the approach of theoretical statisticians. I will talk about some uses and misuses of P values, and theoretical vs. practical approaches to inferential errors. I will argue that statistical "significance" is not a thing, and discuss some practical and some aspirational ideas for improving the language we use to discuss statistics.

----------------------------------------------------------------------

EXTRA To-do

* plain.set

* front material

* ideas (material from evaluation, article titles and text)

* Choose stream (extra DEFHEADS, like STATS)

----------------------------------------------------------------------

NOFRAME

\newcommand{\jdtitle}
{Statistical philosophy and the language of significance}

{Bridging between science and statistical theory}

\newcommand{\jdauth}{Jonathan Dushoff, McMaster University}
\newcommand{\jdsub}{}
\newcommand{\years}{2012--2018} 
\newcommand{\wdate}{U. Chicago, Oct 2018}

----------------------------------------------------------------------

EXTRA

ICI3DTHEME

----------------------------------------------------------------------

WORKSHOP

----------------------------------------------------------------------

EXTRA

Topics

	How statistics fits into science (statistical philosophy)

	The role of P values (and the cult of P values)

	Theoretical vs applied perspectives on error

	What's significant about significance?

----------------------------------------------------------------------

STATS

Vitamin A

	We compare health indicators of children treated or not treated with
	vitamin A supplements 

	Possible goals

		\emph{Estimate:} how much taller (or shorter) are the treated
		children on average?

		\emph{Confirmation:} are we sure that the supplements are helping
		(or hurting)?

		\emph{Range of estimates:} how much do we think the supplement is
		helping?

----------------------------------------------------------------------

STATS

P values and confidence intervals

	We use \emph{P values} to say how sure we are that we have seen a positive 
	effect

	We use \emph{confidence intervals} to say what we think is going on
	(with a certain level of confidence)

	P values are \emph{over-rated}

	\emph{Never} use a high P value as evidence for anything, e.g.:
	
		that an effect is small

		that two quantities are similar

----------------------------------------------------------------------

STATS

Vitamin A questions

	Is vitamin A good for these children?

	How sure are we?

	How good do we think it is?

	How sure are we about that?

----------------------------------------------------------------------

P values

	We compare health indicators of children treated or not treated with
	vitamin A supplements 

	What does it mean if I find a ``significant P value" for some effect
	in this experiment?

		ANS The difference is unlikely to be due to chance

		ANS So what!  I already know vitamin A has strong effects on
		metabolism

	If I'm certain that the true answer isn't exactly zero, why do I
	want the P value anyway?

----------------------------------------------------------------------

Confidence intervals

BC

CFIG vitamins.Rout-0.pdf

NC

	What do these results mean?

	Which are significant?

EC

----------------------------------------------------------------------

Confidence intervals and P values

BC

PRESENT CFIG vitamins.Rout-1.pdf

NC

	A high P value means we can't see the \emph{sign} of the effect clearly

	A low P value means we can

EC

----------------------------------------------------------------------

The meaning of P values

PIC DBFIG 0.8 webpix/fog.jpg 1 webpix/clear.jpg

	More broadly, a P value measures whether we are seeing
	\emph{something} clearly

		It's usually the sign ($\pm$) of some quantity, but doesn't need to be

----------------------------------------------------------------------

Types of Error

	Type I (\emph{False positive:}) concluding there is an effect when
	there isn't one

		This doesn't happen in biology.  There is always an effect.

		This is a defensible belief, and also an unfalsifiable one

	Type II (\emph{False negative:}) concluding there is no effect when
	there really is

		This \emph{should} never happen in biology, because we should never
		conclude there is no effect

		In fact, it happens all the time

----------------------------------------------------------------------

RHEAD Types of Error

	Type III Error is the error of using numerical codes for things that have perfectly good simple names

	Just say ``false positive'' or ``false negative'' when possible

----------------------------------------------------------------------

Errors in applied studies

BC

	\emph{Sign error:} if I think an effect is positive, when it's really
	negative (or vice versa)

	\emph{Magnitude error:} if I think an effect is small, when it's
	really large (or vice versa)

	Confidence intervals clarify all of this

NC

SIDEFIG webpix/error.jpg

EC

----------------------------------------------------------------------

Errors in theoretical studies

	\emph{False positive:} in the hypothetical case that the
	effect is exactly zero, what is the probability of falsely finding
	an effect?

		Should be less than or equal to my nominal significance value

		This is the gold standard for statistical validity

	\emph{False negative:} what is the probability of failing
	to find an effect that is there?

		Requires you specify a hypothetical effect \emph{size}

			This is a \emph{scientific} judgment

		This is a good way to analyze power
	
	You should do these analyses \emph{before} you collect data, not after

----------------------------------------------------------------------

Low P values

BC

	If I have a low P value I can see something clearly

	But it's usually better to focus on what I see than the P value

NC

SIDEFIG webpix/clear.jpg

EC


----------------------------------------------------------------------

High P values

BC

	If I have a high P value, there is something I \emph{don't} see
	clearly

	It \emph{may be} because this effect is small

	High P values should \emph{not} be used to advance your conclusion

NC

SIDEFIG webpix/fog.jpg

EC

----------------------------------------------------------------------

Are high P values evidence?

	What causes them?

		\textbf{Small differences}

		Less data

		More noise

		An inappropriate model

	A lower P value means that your evidence for difference is better

	A higher P value means that your evidence for similarity is
	better -- or worse!

----------------------------------------------------------------------

Annualized flu deaths

BC

CFIG flu.Rout-0.pdf

NC

	Why is weather not causing deaths at this time scale?

EC

----------------------------------------------------------------------

DEFHEAD ... with confidence intervals

BC

CFIG flu.Rout-1.pdf

NC

	\textbf{Never} say: A is significant and B isn't, so $A>B$

	\textbf{Instead:} Construct a statistic for the hypothesis $A>B$

EC

----------------------------------------------------------------------

Small effects

	Evidence that an effect is small:

		We can't even tell the sign!

		It looks small

		We are confident that it's small

	The first is most common
	
		-- and the worst

----------------------------------------------------------------------

STATS

Syllogisms

BC

	All men are mortal

	Justin Trudeau is mortal

	Therefore, Justin Trudeau is a man

NC

SIDEFIG webpix/trudeau.jpg

EC

----------------------------------------------------------------------

STATS

Syllogisms

BC

	All men are mortal

	Fanny the elephant is mortal

	Therefore, Fanny the elephant is a man

NC

SIDEFIG webpix/fanny.jpg

EC

----------------------------------------------------------------------

STATS

Bad logic

	A lot of statistical practice works this way:

		bad logic in service of conclusions that are (usually) correct

	This sort of statistical practice leads in the aggregate to bad
	science

	The logic can be fixed

----------------------------------------------------------------------

PSLIDE Flu masks 

DBFIG 0.8 webpix/N95.jpg 0.7 webpix/surgical.jpg

----------------------------------------------------------------------

Flu mask example

	People who work in respiratory clinics sometimes have to wear bulky,
	uncomfortable, expensive masks

	They would like to switch to simpler masks, if those will do the job

	How can this be tested statistically?  We don't want the masks to be
	``different".

		Use a confidence interval

		Decide how big a level is acceptable, and construct a P value for
		the hypothesis that this level is excluded!

----------------------------------------------------------------------

Study results

FIG masks.Rout-2.pdf

----------------------------------------------------------------------

RHEAD Non-inferiority trial

BC

PRESENT CFIG masks.Rout-0.pdf

NC

	Is the new mask ``good enough"?

	What's our standard for that?

EC

----------------------------------------------------------------------

Non-inferiority trial

BC

CFIG masks.Rout-1.pdf

NC

	We can even attach a P value by basing it on the ``right" statistic.

	The right statistic is the thing whose sign we want to know:

		The difference between the observed effect and the standard we
		chose

EC

----------------------------------------------------------------------

Making decisions

FIG webpix/squint.jpg

REMARK How much should I squint?

----------------------------------------------------------------------

Differences

	\textbf{Never} say: A is significant and B isn't, so $A>B$

	\textbf{Instead:} Construct a statistic for the hypothesis $A>B$

		Reparameterize, study interactions

	The Difference Between ``Significant" and ``Not Significant" is not Itself
	Statistically Significant

		CREDIT Gelman and Stern

----------------------------------------------------------------------

Model simplification

BC

	It's not OK to use high P values as a standard for simplifying models

	So how do we simplify?

		For prediction: information criteria

		For inference: ???

			A priori approaches (including Bayesian priors)

			Experiments

	REMARK This lunch is not free

NC

CFIG webpix/lunch.jpg

EC

----------------------------------------------------------------------

Big data

	P values are rarely good for filtering

		We usually want to know what's big or biologically important

		Not what we've seen clearly

	Beware of approaches that calculate many P values in parallel

	This is the cult of the P value (all statistics must be based on P values)

----------------------------------------------------------------------

Language

WIDEFIG my_images/null.png

----------------------------------------------------------------------

Bad language

	Null effects of boot camps

		ANS Wrong!

	Lung capacity in deer-mouse populations is not correlated with elevation

		ANS Yes, it is!

	As expected, the placebo group did not differ significantly from the control
	group

		ANS Why would that be good?

	B and B showed that there is no statistically significant
	difference in sexual risk behaviour between men with and without clinic
	access in Zambia

		ANS No, they didn't

		ANS Statistical significance is a property of the \emph{study} (and the
		sample population), never of real groups (or the idealized population)

----------------------------------------------------------------------

Confusion

WIDEFIG my_images/jelly_beans.png

----------------------------------------------------------------------

Improving language

	\textbf{Wrong:} This treatment does not have a statistically significant
	effect

	\textbf{Standard:} We found that this treatment has no statistically
	significant effect

	\textbf{Better:} We did not find a statistically significant effect of this
	treatment

	\textbf{Best} ??

----------------------------------------------------------------------

Is statistical ``significance'' a thing?

WIDEFIG my_images/significance.png

	ANS It may be a thing

	ANS But it's not much to do with the normal meaning of significance

----------------------------------------------------------------------

Fish hormones

BC

	Male fish subject to polluted water have more female hormones than controls

		P$<$0.05

		A significant effect!

	Is it a significant amount of hormone? How much hormone is it?

NC

HFIG 0.4 webpix/deer_island.jpg

EC

----------------------------------------------------------------------

What do P values measure?

PIC DBFIG 0.8 webpix/fog.jpg 1 webpix/clear.jpg

	ANS Clarity!

	ANS We should call it that

----------------------------------------------------------------------

Another way to talk

	As expected, the sign of the difference between the placebo group and
	controls was unclear

	Unclear effects of boot camps

	The direction of correlation between lung capacity and elevation in
	deer-mouse populations is unclear

	B and B showed that there is an unclear difference in sexual risk
	behaviour between men with and without clinic access in Zambia

----------------------------------------------------------------------

Improving language

	\textbf{Wrong:} This treatment does not have a statistically significant
	effect

	\textbf{Standard:} We found that this treatment has no statistically
	significant effect

	\textbf{Better:} We did not find a statistically significant effect of this
	treatment

	\textbf{New:} We did not \emph{see} a statistically \emph{clear}  effect of
	this treatment

		The effect of this treatment 
		was not statistically \emph{clear} in this study

----------------------------------------------------------------------

Is it possible?

	It's hard to get people to change language

	But you can probably change your language (if you keep the P values)

		We found a statistically clear increase (P=0.02) in blood iron in the
		vitamin-supplement group

		The direction of association between lung capacity and elevation was not
		statistically clear (P=0.43)

		B and B did not see a statistically clear difference in sexual risk
		behaviour between men with and without clinic access in Zambia (P=0.1)

	Confidence intervals are still better, when possible

----------------------------------------------------------------------

STATS Hard questions

PIC FIG webpix/QuestionAnswers.jpg

	Answers are not always easy

----------------------------------------------------------------------

Statistical philosophy

SUBH Advice for scientists

	Statistics are not a magic machine that gives you the right answer

	If you are to be a serious scientist in a noisy world, you should
	have your own philosophy of statistics

		Be pragmatic: your goal is to do science, not get caught by
		theoretical considerations

		Be honest: it's harder than it sounds.  

----------------------------------------------------------------------

Honesty

	You can always keep analyzing until you find a ``significant''
	(or ``clear'') result

		If you do this you will make a lot of mistakes

	You may also keep analyzing until you find a result that you already
	``know'' is true. 

		This is confirmation bias; you're probably right, but your project is not
		advancing science

	Good practice

		Keep a data-analysis journal

		Start \emph{before} you look at the data

----------------------------------------------------------------------

Summary

	P values are over-rated

	High P values should not be used as evidence for anything ever.

		They can provide indirect evidence. Wonderful. Find the direct evidence
		and use that instead.

	Use effect sizes and confidence intervals when you can

	Otherwise, find ways to make low P values do the work
	
		Non-inferiority tests, interactions

		Don't rely on unclear information

----------------------------------------------------------------------

STATS RHEAD Summary

	Statistics are a key component of data-based science

		You should think about statistical analysis from the beginning of your
		project

	You need a basic understanding of statistical principles

	You need your own statistical philosophy

----------------------------------------------------------------------

Language

	Language is important and feeds misunderstanding

	Even if you are not misled, others will be

	Use language clearly:

		We found no difference

		⇒ We did not see a clear difference 

	Consider abandoning the language of statistical ``significance''

	\emph{Definitely} abandon the language of statistical ``equivalence''
